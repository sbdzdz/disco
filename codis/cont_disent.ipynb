{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.9.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from codis.data import InfiniteDSprites, Latents\n",
    "from codis.visualization import draw_batch_grid\n",
    "\n",
    "from codis.models.beta_vae_v2 import BetaVAEV2\n",
    "from typing import List, Optional\n",
    "from codis.models.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.9886, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(711.3248, grad_fn=<DivBackward0>)\n",
      "tensor(0.2101, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m BETA       \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     88\u001b[0m model \u001b[39m=\u001b[39m CBetaVAE(latent_dim\u001b[39m=\u001b[39mLATENT_DIM, num_channels\u001b[39m=\u001b[39mN_CHANNELS, beta\u001b[39m=\u001b[39mBETA)\n\u001b[0;32m---> 89\u001b[0m train_loop(model, image_size\u001b[39m=\u001b[39;49mIMAGE_SIZE, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE)\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, image_size, Nround, Niter, batch_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     76\u001b[0m     loss \u001b[39m=\u001b[39m model(X, Z)\n\u001b[0;32m---> 77\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     78\u001b[0m     opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     79\u001b[0m eval_learning_so_far(model)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "class ClassIncrementalInfiniteDSprites(InfiniteDSprites):\n",
    "    \"\"\"Infinite dataset of procedurally generated shapes undergoing transformations.\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__seen_shapes = []\n",
    "        self.change_class()\n",
    "\n",
    "    @property\n",
    "    def num_seen_classes(self):\n",
    "        return len(self.__seen_shapes)\n",
    "    \n",
    "    def change_class(self):\n",
    "        self.__current_shape = self.generate_shape()\n",
    "        self.__seen_shapes.append(self.__current_shape)\n",
    "    \n",
    "    def sample_latents_for_shape(self, shape):\n",
    "        \"\"\"Sample a random set of latents.\"\"\"\n",
    "        return Latents(\n",
    "            color=np.random.choice(self.ranges[\"color\"]),\n",
    "            shape=shape,\n",
    "            scale=np.random.choice(self.ranges[\"scale\"]),\n",
    "            orientation=np.random.choice(self.ranges[\"orientation\"]),\n",
    "            position_x=np.random.choice(self.ranges[\"position_x\"]),\n",
    "            position_y=np.random.choice(self.ranges[\"position_y\"]),\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Generate an infinite stream of images and latent vectors.\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            An infinite stream of (image, latents) tuples.\"\"\"\n",
    "        while True:\n",
    "            latents = self.sample_latents_for_shape(self.__current_shape)\n",
    "            image   = self.draw(latents)\n",
    "            yield image, latents\n",
    "\n",
    "\n",
    "class CBetaVAE(BetaVAEV2):\n",
    "    \"\"\"The Î²-VAE model class.\"\"\"\n",
    "\n",
    "    def __init__(self, in_width: int = 64, in_channels: int = 1, latent_dim: int = 64, \\\n",
    "        num_channels: Optional[List] = None, beta: float = 1.0, H:int=128, L:int=2, act:str='elu') -> None:\n",
    "        super().__init__(in_width=in_width, in_channels=in_channels, latent_dim=latent_dim, num_channels=num_channels, beta=beta)\n",
    "        self.regressor = MLP(latent_dim, 4, L=L, H=H, act=act)\n",
    "    \n",
    "    def forward(self, X, Z):\n",
    "        ''' Inputs:\n",
    "                X - [N,C,W,H]\n",
    "                Z - Latents\n",
    "        '''\n",
    "        Xhat, mu, log_std = super().forward(X) # [N,C,W,H], [N,q], [N,q]\n",
    "        Z = torch.stack([Z.scale, Z.orientation, Z.position_x, Z.position_y],-1) # N,4\n",
    "        latent_reg_loss = (Z-self.regressor(mu)).pow(2).sum(-1).mean(0)\n",
    "        reconstruction_loss = self.reconstruction_loss(X,Xhat)\n",
    "        kl_divergence = self.kl_loss(mu,log_std)\n",
    "        print(latent_reg_loss)\n",
    "        print(reconstruction_loss)\n",
    "        print(kl_divergence)\n",
    "    \n",
    "def eval_learning_so_far(model):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def train_loop(model, image_size=64, Nround=10, Niter=1000, batch_size=64):\n",
    "    dataset = ClassIncrementalInfiniteDSprites(image_size=image_size)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for i in range(Nround):\n",
    "        for i,(X,Z) in enumerate(data_loader):\n",
    "            opt.zero_grad()\n",
    "            loss = model(X, Z)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        eval_learning_so_far(model)\n",
    "        dataset.change_class()\n",
    "\n",
    "LATENT_DIM = 20\n",
    "N_CHANNELS = [32, 64, 128, 256]\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 2\n",
    "BETA       = 5\n",
    "\n",
    "model = CBetaVAE(latent_dim=LATENT_DIM, num_channels=N_CHANNELS, beta=BETA)\n",
    "train_loop(model, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
